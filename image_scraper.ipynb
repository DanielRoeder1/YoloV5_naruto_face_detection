{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting face images from fandom website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting images from the Naruto fan wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images(fandom_link, selector_overview, selector_character_page):\n",
    "    # alphabetic character overview page -> character page -> character picture\n",
    "    site_pointer = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"ยก\"]\n",
    "    counter = 0\n",
    "    # collect character links\n",
    "    character_links = []\n",
    "    for p in tqdm(site_pointer):\n",
    "        soup = bs(re.get(fandom_link+p).text)\n",
    "        for link in soup.select(selector_overview):\n",
    "            character_links.append(fandom_link.split(\"/wiki\")[0]+link.get(\"href\"))\n",
    "        \n",
    "    #remove duplicates\n",
    "    fandom_name = fandom_link.split(\".fandom\")[0].split(\"//\")[1]\n",
    "    try:\n",
    "        os.mkdir(fandom_name)\n",
    "    except:\n",
    "        print(\"folder already exists\")\n",
    "    \n",
    "    character_links = list(set(character_links))\n",
    "    for character_link in tqdm(character_links):\n",
    "        # Grab image links from character profile website\n",
    "        img_links = [img_link.get(\"src\").split(\"/revision\")[0] for img_link in bs(re.get(character_link).text).select(selector_character_page)]\n",
    "        for img_link in img_links:\n",
    "            try:\n",
    "                response = re.get(img_link)\n",
    "            except:\n",
    "                print(\"Error\")\n",
    "                continue\n",
    "            #create folder using fandom name\n",
    "            file = open(fandom_name+\"/\"+str(counter)+\".png\", \"wb\")\n",
    "            file.write(response.content)\n",
    "            file.close()\n",
    "            counter+=1\n",
    "\n",
    "# Avatar           \n",
    "#fandom_link = \"https://avatar.fandom.com/wiki/Category:Characters?from=\"\n",
    "#selector_overview = \".category-page__member-link\"\n",
    "#selector_character_page = \".pi-image-thumbnail\"\n",
    "\n",
    "# Naruto \n",
    "fandom_link = \"https://naruto.fandom.com/wiki/Category:Characters?from=\"\n",
    "selector_overview = \".category-page__member-link\"\n",
    "selector_character_page = \".imagecell img\"\n",
    "\n",
    "collect_images(fandom_link, selector_overview, selector_character_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting images from Pinterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pinterest_scraper:\n",
    "    def __init__(self, username, password):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.image_links = []\n",
    "        self.keyword = \"\"\n",
    "        self.image_links_collection = []\n",
    "        \n",
    "    def startup(self,keyword):\n",
    "        self.keyword = keyword\n",
    "        self.driver.get(\"https://www.pinterest.com/\")\n",
    "        time.sleep(2)\n",
    "        self.login()\n",
    "        self.driver.find_element_by_xpath(\"\"\"//*[@id=\"searchBoxContainer\"]/div/div/div[2]/input\"\"\").send_keys(keyword)\n",
    "        self.driver.find_element_by_xpath(\"\"\"//*[@id=\"searchBoxContainer\"]/div/div/div[1]/input\"\"\").send_keys(Keys.RETURN)\n",
    "\n",
    "    def login(self):\n",
    "        self.driver.find_element_by_css_selector('.RCK').click()\n",
    "        time.sleep(2)\n",
    "        self.driver.find_element_by_id('email').send_keys(self.username)\n",
    "        self.driver.find_element_by_id('password').send_keys(self.password)\n",
    "        self.driver.find_element_by_css_selector('.SignupButton').click()\n",
    "        time.sleep(4)\n",
    "\n",
    "    def collect_image_links(self,num_images, save = False, link_file = None):\n",
    "        if link_file is not None:\n",
    "            with open(link_file, 'rb') as f:\n",
    "                already_collected = pickle.load(f)\n",
    "        else:\n",
    "            already_collected = []\n",
    "                \n",
    "        while len(self.image_links) < num_images:\n",
    "            t_0 = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            html = self.driver.page_source\n",
    "            soup = bs(html)\n",
    "            for image in soup.select(\".L4E.MIw\"):\n",
    "                image_link = image.get(\"src\")\n",
    "                if \"236x\" in image_link:\n",
    "                    image_link = image_link.replace(\"236x\",\"originals\")\n",
    "                    if image_link not in already_collected:\n",
    "                        self.image_links.append(image_link)\n",
    "                    else:\n",
    "                        print(\"link already collected\")\n",
    "            self.driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "            time.sleep(3)\n",
    "            if t_0 == self.driver.execute_script(\"return document.body.scrollHeight\"):\n",
    "                print(\"breaking\")\n",
    "                break\n",
    "        if save:\n",
    "            with open(\"image_links_\"+self.keyword+\".pickle\", 'wb') as handle:\n",
    "                pickle.dump(self.image_links, handle)\n",
    "        self.image_links_collection.extend(self.image_links)\n",
    "        self.image_links = []\n",
    "        return list(set(self.image_links))[:num_images]\n",
    "    \n",
    "    def download_images(self):\n",
    "        try:\n",
    "            os.mkdir(\"images_\"+self.keyword)\n",
    "        except:\n",
    "                print(\"folder already exists\")\n",
    "\n",
    "        for counter, link in tqdm(enumerate(self.image_links)):\n",
    "            response = re.get(link)\n",
    "            \n",
    "            soup = bs(response.content)\n",
    "            if soup.select(\"code\") != []:\n",
    "                print(\"access denied\")\n",
    "                link = link.replace(\"originals\",\"564x\")\n",
    "                response = re.get(link)\n",
    "\n",
    "            file = open(\"images_\"+self.keyword+\"/\"+str(counter)+\".jpg\", \"wb\")\n",
    "            file.write(response.content)\n",
    "            file.close()\n",
    "            time.sleep(.2)\n",
    "            counter+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"\"\n",
    "password = \"\"\n",
    "\n",
    "ps = pinterest_scraper(username, password)\n",
    "ps.startup(\"naruto characters\")\n",
    "ps.collect_image_links(1000, True)\n",
    "ps.download_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
